<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" />

    <!-- Generated with Sphinx 6.1.3 and Furo 2022.12.07 -->
        <title>capsa.bias.histogramvae - capsa documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?digest=91d0f0d1c444bdcb17a68e833c7a53903343c195" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../index.html"><div class="brand">capsa  documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../../index.html">
  
  
  <span class="sidebar-brand-text">capsa  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../introduction/index.html">üëã Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/installation.html">üíæ Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../risk_metrics/index.html">‚≠êÔ∏è Risk Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/basic_usage.html">üé¨ Basic Usage</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../tutorials/index.html">üë©‚Äçüè´ Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/notebooks/1_Ensemble-Classification.html">Ensemble Wrapper (Classification)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/notebooks/2_Histogram-Classification.html">Histogram Wrapper (Classification)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/notebooks/3_MVE-Classification.html">MVE Wrapper (Classification)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/notebooks/4_MVE-Regression.html">MVE Wrapper (Regression)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/notebooks/5_High-Dimensional-Depth.html">High Level Introduction to Capsa with a Real World Problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/notebooks/6_OOD-Detection.html">Anomaly Detection (Advanced)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/notebooks/7_Composability.html">Composability (Advanced)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api_documentation/index.html">‚Äçüíª Metric Wrapper API</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_documentation/BaseWrapper.html">BaseWrapper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_documentation/RiskTensor.html">RiskTensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_documentation/MVEWrapper.html">MVEWrapper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_documentation/VAEWrapper.html">VAEWrapper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_documentation/EnsembleWrapper.html">EnsembleWrapper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_documentation/DropoutWrapper.html">DropoutWrapper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_documentation/HistogramWrapper.html">HistogramWrapper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_documentation/HistogramVAEWrapper.html">HistogramVAEWrapper</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../contribute/index.html">üßø Contribute</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <h1>Source code for capsa.bias.histogramvae</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">sample</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="n">copy_layer</span><span class="p">,</span> <span class="n">_get_out_dim</span>
<span class="kn">from</span> <span class="nn">..base_wrapper</span> <span class="kn">import</span> <span class="n">BaseWrapper</span>
<span class="kn">import</span> <span class="nn">tensorflow_probability</span> <span class="k">as</span> <span class="nn">tfp</span>



<span class="k">def</span> <span class="nf">kl</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">log_std</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
        <span class="mi">1</span> <span class="o">+</span> <span class="n">log_std</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_std</span><span class="p">)),</span>
        <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span>

<span class="k">def</span> <span class="nf">mse</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
        <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">axis</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
        <span class="n">keepdims</span><span class="o">=</span><span class="p">(</span><span class="kc">False</span> <span class="k">if</span> <span class="n">reduce</span> <span class="k">else</span> <span class="kc">True</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span> <span class="k">if</span> <span class="n">reduce</span> <span class="k">else</span> <span class="n">mse</span>

<div class="viewcode-block" id="HistogramVAEWrapper"><a class="viewcode-back" href="../../../api_documentation/HistogramVAEWrapper.html#capsa.HistogramVAEWrapper">[docs]</a><span class="k">class</span> <span class="nc">HistogramVAEWrapper</span><span class="p">(</span><span class="n">BaseWrapper</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Combines the functionalities of both HistogramWrapper and VAEWrapper. This is done by converting a given base_model into Variational AutoEncoder architecture, with latent dimension defined by the given parameter ``latent_dim``.</span>

<span class="sd">    VAEs are typically used to learn a robust, low-dimensional representation</span>
<span class="sd">    of the latent space. They can be used as a method of estimating epistemic</span>
<span class="sd">    uncertainty by using the reconstruction loss MSE(x, x_hat) - in cases of</span>
<span class="sd">    out-of-distribution data, samples that are hard to learn, or underrepresented</span>
<span class="sd">    samples, we expect that the VAE will have high reconstruction loss, since the</span>
<span class="sd">    mapping to the latent space will be less accurate. Conversely, when the model</span>
<span class="sd">    is very familiar with the features being fed in, or the data is in distribution,</span>
<span class="sd">    we expect the latent space mapping to be robust and the reconstruction loss to be low.</span>

<span class="sd">    A histogram distribution is constructed from the mean layer of the VAE architecture. This histogram is used to estimate a    </span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="HistogramVAEWrapper.__init__"><a class="viewcode-back" href="../../../api_documentation/HistogramVAEWrapper.html#capsa.HistogramVAEWrapper.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_model</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span><span class="n">queue_size</span><span class="p">,</span><span class="n">num_bins</span><span class="p">,</span><span class="n">decoder</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        base_model : tf.keras.Model</span>
<span class="sd">            A model to be transformed into a risk-aware variant.</span>
<span class="sd">        decoder : tf.keras.Model, default None</span>
<span class="sd">            To construct the VAE for any given model in capsa, we use the feature extractor as the encoder,</span>
<span class="sd">            and reverse the feature extractor automatically when possible to create a decoder.</span>
<span class="sd">        latent_dim : int</span>
<span class="sd">            Defines the dimension of latent-space. Making this very small can cause the bottleneck to lose too much information, resulting in high reconstruction loss. On the contrary, making it too big can cause the passing information to not become compressed enough, resulting in less-meaningful latent features.</span>
<span class="sd">        queue_size : int</span>
<span class="sd">            The size of the internal queue data-structure to use for the histogram</span>
<span class="sd">        num_bins : int</span>
<span class="sd">            How many bins to use in the histogram</span>

<span class="sd">        Attributes</span>
<span class="sd">        ----------</span>
<span class="sd">        metric_name : str</span>
<span class="sd">            Represents the name of the metric wrapper.</span>
<span class="sd">        mean_layer : tf.keras.layers.Layer</span>
<span class="sd">            Used to predict mean of the diagonal gaussian representing the latent space.</span>
<span class="sd">        log_std_layer : tf.keras.layers.Layer</span>
<span class="sd">            Used to predict variance of the diagonal gaussian representing the latent space.</span>
<span class="sd">        feature_extractor : tf.keras.Model</span>
<span class="sd">            Creates a ``feature_extractor`` by removing last layer from the ``base_model``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">HistogramVAEWrapper</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">base_model</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span> <span class="o">=</span> <span class="s2">&quot;vae&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_std_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue_built</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue_size</span> <span class="o">=</span> <span class="n">queue_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_bins</span> <span class="o">=</span> <span class="n">num_bins</span>

        <span class="k">if</span> <span class="n">decoder</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
        <span class="c1"># reverse model if we can, accept user decoder if we cannot</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span><span class="p">,</span> <span class="s2">&quot;layers&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reverse_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;If you provide a subclassed model, </span><span class="se">\</span>
<span class="s2">                the decoder must also be specified&quot;</span>
            <span class="p">)</span></div>

<div class="viewcode-block" id="HistogramVAEWrapper.call"><a class="viewcode-back" href="../../../api_documentation/HistogramVAEWrapper.html#capsa.HistogramVAEWrapper.call">[docs]</a>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_risk</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass of the model. The epistemic risk estimate could be calculated differently:</span>
<span class="sd">        by running either (1) deterministic or (2) stochastic forward pass.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : tf.Tensor</span>
<span class="sd">            Input.</span>
<span class="sd">        training : bool, default False</span>
<span class="sd">            Can be used to specify a different behavior in training and inference.</span>
<span class="sd">        return_risk : bool, default True</span>
<span class="sd">            Indicates whether or not to output a risk estimate in addition to the model&#39;s prediction.</span>
<span class="sd">        T : int, default 1</span>
<span class="sd">            Defines will the model be run deterministically or stochastically, and the number of times</span>
<span class="sd">            to sample from the latent space (if run stochastically).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        out : capsa.RiskTensor</span>
<span class="sd">            Risk aware tensor, contains both the predicted label y_hat (tf.Tensor) and the epistemic</span>
<span class="sd">            uncertainty estimate (tf.Tensor).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="p">)</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_layer</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_risk</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y_hat</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_layer</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
            <span class="n">log_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_std_layer</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

            <span class="c1">#Keras Model.build doesn&#39;t work due to train_step calling loss_fn instead of the model, we need to find a solution to that in the future to remove the horrible next 3 lines of code</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_built</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">build_queue</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">queue_built</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_histogram_probability</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>

            <span class="c1"># deterministic</span>
            <span class="k">if</span> <span class="n">T</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">rec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">training</span><span class="p">)</span>
                <span class="n">epistemic</span> <span class="o">=</span> <span class="n">mse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">rec</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">y_hat</span><span class="p">,</span><span class="n">epistemic</span><span class="p">,</span><span class="n">bias</span>

            <span class="c1"># stochastic</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">recs</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">T</span><span class="p">:</span>
                    <span class="n">sampled_latent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">log_std</span><span class="p">)</span>
                    <span class="n">recs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">sampled_latent</span><span class="p">))</span>
                <span class="n">std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_std</span><span class="p">(</span><span class="n">recs</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">y_hat</span><span class="p">,</span><span class="n">std</span><span class="p">,</span><span class="n">bias</span></div>



<div class="viewcode-block" id="HistogramVAEWrapper.loss_fn"><a class="viewcode-back" href="../../../api_documentation/HistogramVAEWrapper.html#capsa.HistogramVAEWrapper.loss_fn">[docs]</a>    <span class="k">def</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the VAE loss by sampling and then feeding the latent vector</span>
<span class="sd">        through the decoder.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : tf.Tensor</span>
<span class="sd">            Input.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        loss : tf.Tensor</span>
<span class="sd">            Float, reflects how well does the algorithm perform given the ground truth label,</span>
<span class="sd">            predicted label and the metric specific loss function.</span>
<span class="sd">        y_hat : tf.Tensor</span>
<span class="sd">            Predicted label.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

        <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_layer</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean_layer</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="n">log_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_std_layer</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>


        <span class="c1">#Keras Model.build doesn&#39;t work due to train_step calling loss_fn instead of the model, we need to find a solution to that in the future to remove the horrible next 3 lines of code</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_built</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>    
            <span class="bp">self</span><span class="o">.</span><span class="n">build_queue</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">queue_built</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">add_queue</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
        <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_histogram_probability</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>

        <span class="n">sampled_latent</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">log_std</span><span class="p">)</span>
        <span class="n">rec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">sampled_latent</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">kl</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">log_std</span><span class="p">)</span> <span class="o">+</span> <span class="n">mse</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">rec</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">bias</span></div>
    

<div class="viewcode-block" id="HistogramVAEWrapper.train_step"><a class="viewcode-back" href="../../../api_documentation/HistogramVAEWrapper.html#capsa.HistogramVAEWrapper.train_step">[docs]</a>    <span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The logic for one training step.</span>

<span class="sd">        Adds the compiled loss such that the models that subclass this class don&#39;t need to explicitly add it.</span>
<span class="sd">        Thus the ``metric_loss`` returned from such a model is not expected to reflect the compiled</span>
<span class="sd">        (user specified) loss -- because it is added here.</span>

<span class="sd">        Note: This method could be overwritten in subclasses, but the rule of thumb is to try to avoid</span>
<span class="sd">        overwriting it unless it&#39;s absolutely necessary, as e.g. in the ``EnsembleWrapper`` (functionality</span>
<span class="sd">        of that wrapper cannot be achieved without overwriting ``BaseWrapper``&#39;s ``train_step``). But in general,</span>
<span class="sd">        try to only overwrite ``BaseWrapper``&#39;s ``loss_fn`` and ``call`` methods -- in most of the cases it</span>
<span class="sd">        should be enough.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : tuple</span>
<span class="sd">            (x, y) pairs, as in the regular Keras ``train_step``.</span>
<span class="sd">        prefix : str, default None</span>
<span class="sd">            Used to modify entries in the dict of `keras metrics &lt;https://keras.io/api/metrics/&gt;`_</span>
<span class="sd">            such that they reflect the name of the metric wrapper that produced them (e.g., mve_loss: 2.6763).</span>
<span class="sd">            Note, keras metrics dict contains e.g. loss values for the current epoch/iteration</span>
<span class="sd">            not to be confused with what we call &quot;metric wrappers&quot;.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        keras_metrics : dict</span>
<span class="sd">            `Keras metrics &lt;https://keras.io/api/metrics/&gt;`_.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">data</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">t</span><span class="p">:</span>
            <span class="n">metric_loss</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">compiled_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_loss</span><span class="p">(</span>
                <span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">regularization_losses</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span>
            <span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">metric_loss</span> <span class="o">+</span> <span class="n">compiled_loss</span>

        <span class="n">trainable_vars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">trainable_vars</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">trainable_vars</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">compiled_metrics</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
        <span class="n">prefix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span> <span class="k">if</span> <span class="n">prefix</span> <span class="o">==</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">prefix</span>
        <span class="n">keras_metrics</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_compiled_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span>
        <span class="p">}</span>
        <span class="n">keras_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_wrapper_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span>


        <span class="c1">#Possible area to add DB-VAE additions: the variable ``bias`` is available in this scope</span>


        <span class="k">return</span> <span class="n">keras_metrics</span></div>


        
<div class="viewcode-block" id="HistogramVAEWrapper.sampling"><a class="viewcode-back" href="../../../api_documentation/HistogramVAEWrapper.html#capsa.HistogramVAEWrapper.sampling">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">sampling</span><span class="p">(</span><span class="n">z_mean</span><span class="p">,</span> <span class="n">z_log_var</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Samples from the latent space defied by ``z_mean`` and ``z_log_var``.</span>
<span class="sd">        Uses the reparameterization trick to allow to backpropagate through</span>
<span class="sd">        the stochastic node.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        z_mean : tf.Tensor</span>
<span class="sd">            Mean of the diagonal gaussian representing the latent space.</span>
<span class="sd">        z_log_var : tf.Tensor</span>
<span class="sd">            Log variance of the diagonal gaussian representing the latent space.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        sampled_vector : tf.Tensor</span>
<span class="sd">            Vector sampled from the latent space according to the predicted parameters</span>
<span class="sd">            of the normal distribution.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">epsilon</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">z_mean</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">z_mean</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">z_log_var</span><span class="p">)</span> <span class="o">*</span> <span class="n">epsilon</span></div>


    <span class="c1"># Defining a Tensor Queue that saves the last ``queue_size`` values</span>
    <span class="k">def</span> <span class="nf">build_queue</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
        <span class="c1"># Get the shape of the features</span>
        <span class="n">feature_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="c1"># Create a queue with the shape of the features and an index to keep track of how many values are in the queue</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">queue_size</span><span class="p">,</span> <span class="n">feature_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]),</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue_index</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
    <span class="c1"># def build(self,input_shape):</span>
    <span class="c1">#     # Get the shape of the features</span>
    <span class="c1">#     feature_shape = self.mean_layer.output_shape</span>

    <span class="c1">#     # Create a queue with the shape of the features and an index to keep track of how many values are in the queue</span>
    <span class="c1">#     self.queue = tf.Variable(</span>
    <span class="c1">#         tf.zeros([self.queue_size, feature_shape[-1]]), trainable=False</span>
    <span class="c1">#     )</span>
    <span class="c1">#     self.queue_index = tf.Variable(0, trainable=False)</span>


<div class="viewcode-block" id="HistogramVAEWrapper.get_histogram_probability"><a class="viewcode-back" href="../../../api_documentation/HistogramVAEWrapper.html#capsa.HistogramVAEWrapper.get_histogram_probability">[docs]</a>    <span class="k">def</span> <span class="nf">get_histogram_probability</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the probability of each feature in the histogram. This utilizes the internal queue data-structure to calculate the probability.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        features : tf.Tensor</span>
<span class="sd">            Features to calculate probability for.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        logits : tf.Tensor</span>
<span class="sd">            Calculated probabilities for each feature.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">edges</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_histogram_edges</span><span class="p">()</span>

        <span class="n">frequencies</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">value</span><span class="p">(),</span>
            <span class="n">edges</span><span class="p">,</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">extend_lower_interval</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">extend_upper_interval</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Normalize histograms</span>
        <span class="n">hist_probs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">frequencies</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">frequencies</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

        <span class="c1"># Get the corresponding bins of the features</span>
        <span class="n">bin_indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span>
            <span class="n">tfp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">find_bins</span><span class="p">(</span>
                <span class="n">features</span><span class="p">,</span>
                <span class="n">edges</span><span class="p">,</span>
                <span class="n">extend_lower_interval</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">extend_upper_interval</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Multiply probabilities together to compute bias</span>
        <span class="n">second_element</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">features</span><span class="p">)[</span><span class="mi">1</span><span class="p">])],</span> <span class="n">repeats</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">features</span><span class="p">)[</span><span class="mi">0</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">bin_indices</span><span class="p">,</span> <span class="n">second_element</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

        <span class="n">probabilities</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">hist_probs</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probabilities</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span>
            <span class="n">logits</span>
        <span class="p">)</span>  <span class="c1"># log probabilities are the wrong sign if we don&#39;t subtract the mean</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span></div>


    <span class="k">def</span> <span class="nf">add_queue</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>

        <span class="c1"># Get the index of the queue</span>
        <span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_queue_index</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

        <span class="c1"># Add the features to the queue</span>
        <span class="n">queue_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">value</span><span class="p">()</span>
        <span class="n">updated_queue_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tensor_scatter_nd_update</span><span class="p">(</span>
            <span class="n">queue_state</span><span class="p">,</span> <span class="n">updates</span><span class="o">=</span><span class="n">features</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="n">index</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">updated_queue_state</span><span class="p">)</span>


    <span class="c1"># Get the indices of where to insert new features and increment current-index by the length of indices</span>
    <span class="k">def</span> <span class="nf">get_queue_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>

        <span class="c1"># Get the index of the queue</span>
        <span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_index</span><span class="o">.</span><span class="n">value</span><span class="p">()</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">features</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Get the index of the queue</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">index</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;range&quot;</span><span class="p">)</span>

        <span class="c1"># Increment the index by one and assign it to the class variable</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">floormod</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">queue_index</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># Return the old index</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_histogram_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="c1"># Get queue values</span>
        <span class="n">queue_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">queue</span><span class="o">.</span><span class="n">value</span><span class="p">()</span>

        <span class="n">queue_minimums</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_min</span><span class="p">(</span><span class="n">queue_state</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">queue_maximums</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">queue_state</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">edges</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">queue_minimums</span><span class="p">,</span> <span class="n">queue_maximums</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_bins</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">edges</span>

    <span class="k">def</span> <span class="nf">reverse_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">model</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">latent_dim</span><span class="p">)</span>
        <span class="n">i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">while</span> <span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">!=</span> <span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reverse_layer</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">])(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">:</span>
                    <span class="n">original_input</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">input_shape</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reverse_layer</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">original_input</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reverse_layer</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">])(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">i</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">reverse_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">layer</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">layer_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
        <span class="n">unchanged_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">layers</span><span class="o">.</span><span class="n">Activation</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">]</span>
        <span class="c1"># TODO: handle global pooling separately</span>
        <span class="n">pooling_1D</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling1D</span><span class="p">,</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">AveragePooling1D</span><span class="p">,</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">GlobalMaxPooling1D</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="n">pooling_2D</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">,</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">AveragePooling2D</span><span class="p">,</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">GlobalMaxPooling2D</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="n">pooling_3D</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">MaxPooling3D</span><span class="p">,</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">AveragePooling3D</span><span class="p">,</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">GlobalMaxPooling3D</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="n">conv</span> <span class="o">=</span> <span class="p">[</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">,</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv3D</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">:</span>
            <span class="n">config</span><span class="p">[</span><span class="s2">&quot;units&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">input_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">layer_type</span> <span class="ow">in</span> <span class="n">unchanged_layers</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">layer_type</span> <span class="ow">in</span> <span class="n">pooling_1D</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">UpSampling1D</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;pool_size&quot;</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">layer_type</span> <span class="ow">in</span> <span class="n">pooling_2D</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">UpSampling2D</span><span class="p">(</span>
                <span class="n">size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;pool_size&quot;</span><span class="p">],</span>
                <span class="n">data_format</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;data_format&quot;</span><span class="p">],</span>
                <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">layer_type</span> <span class="ow">in</span> <span class="n">pooling_3D</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">UpSampling3D</span><span class="p">(</span>
                <span class="n">size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;pool_size&quot;</span><span class="p">],</span>
                <span class="n">data_format</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;data_format&quot;</span><span class="p">],</span>
                <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">layer_type</span> <span class="ow">in</span> <span class="n">conv</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">output_shape</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">config</span><span class="p">[</span><span class="s2">&quot;filters&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv1DTranspose</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv2DTranspose</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv3D</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">Conv3DTranspose</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div>
</pre></div>
        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, Themis AI Inc
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/scripts/furo.js"></script>
    <script src="../../../_static/tabs.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>