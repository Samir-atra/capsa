{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mitdeeplearning in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.2.0)\n",
      "Requirement already satisfied: regex in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from mitdeeplearning) (2022.7.25)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from mitdeeplearning) (4.62.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from mitdeeplearning) (1.21.2)\n",
      "Requirement already satisfied: gym in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from mitdeeplearning) (0.25.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from gym->mitdeeplearning) (0.0.7)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0; python_version < \"3.10\" in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from gym->mitdeeplearning) (4.12.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from gym->mitdeeplearning) (2.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from importlib-metadata>=4.8.0; python_version < \"3.10\"->gym->mitdeeplearning) (3.8.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 22.2.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Import Tensorflow 2.0\n",
    "import tensorflow as tf\n",
    "\n",
    "import IPython\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from capsa import HistogramCallback, HistogramWrapper, Wrapper, wrap\n",
    "\n",
    "# Download and import the MIT 6.S191 package\n",
    "%pip install mitdeeplearning\n",
    "import mitdeeplearning as mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    # Legacy Python that doesn't verify HTTPS certificates by default\n",
    "    pass\n",
    "else:\n",
    "    # Handle target environment that doesn't support HTTPS verification\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.dropbox.com/s/hlz8atheyozp1yx/train_face.h5?dl=1\n",
      "1263894528/1263889489 [==============================] - 919s 1us/step\n",
      "1263902720/1263889489 [==============================] - 919s 1us/step\n",
      "Opening /Users/sadhanalolla/.keras/datasets/train_face.h5\n",
      "Loading data into memory...\n"
     ]
    }
   ],
   "source": [
    "# Get the training data: both images from CelebA and ImageNet\n",
    "from rsa import verify\n",
    "\n",
    "\n",
    "path_to_training_data = tf.keras.utils.get_file('train_face.h5', 'https://www.dropbox.com/s/hlz8atheyozp1yx/train_face.h5?dl=1')\n",
    "# Instantiate a TrainingDatasetLoader using the downloaded dataset\n",
    "loader = mdl.lab2.TrainingDatasetLoader(path_to_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_training_examples = loader.get_train_size()\n",
    "(images, labels) = loader.get_batch(100)\n",
    "\n",
    "face_images = images[np.where(labels==1)[0]]\n",
    "not_face_images = images[np.where(labels==0)[0]]\n",
    "\n",
    "idx_face = 23 \n",
    "idx_not_face = 9 \n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(face_images[idx_face])\n",
    "plt.title(\"Face\"); plt.grid(False)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(not_face_images[idx_not_face])\n",
    "plt.title(\"Not Face\"); plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the CNN model ###\n",
    "\n",
    "n_filters = 12 # base number of convolutional filters\n",
    "\n",
    "'''Function to define a standard CNN model'''\n",
    "def make_standard_classifier(n_outputs=1):\n",
    "  Conv2D = functools.partial(tf.keras.layers.Conv2D, padding='same', activation='relu')\n",
    "  BatchNormalization = tf.keras.layers.BatchNormalization\n",
    "  Flatten = tf.keras.layers.Flatten\n",
    "  Dense = functools.partial(tf.keras.layers.Dense, activation='relu')\n",
    "\n",
    "  model = tf.keras.Sequential([\n",
    "    Conv2D(filters=1*n_filters, kernel_size=5,  strides=2),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Conv2D(filters=2*n_filters, kernel_size=5,  strides=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(filters=4*n_filters, kernel_size=3,  strides=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Conv2D(filters=6*n_filters, kernel_size=3,  strides=2),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512),\n",
    "    Dense(n_outputs, activation=None),\n",
    "  ])\n",
    "  return model\n",
    "\n",
    "standard_classifier = make_standard_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_classifier.compile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
