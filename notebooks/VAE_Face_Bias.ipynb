{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import h5py\n",
    "import sys\n",
    "import glob\n",
    "import functools\n",
    "from capsa import HistogramWrapper, HistogramCallback, wrap, VAEWrapper\n",
    "from .train_dataloader import TrainingDatasetLoader\n",
    "import mitdeeplearning as mdl\n",
    "from tqdm import tqdm\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 32\n",
    "n_filters=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_standard_classifier(n_outputs=1):\n",
    "    Conv2D = functools.partial(\n",
    "        tf.keras.layers.Conv2D, padding=\"same\", activation=\"relu\"\n",
    "    )\n",
    "    BatchNormalization = tf.keras.layers.BatchNormalization\n",
    "    Flatten = tf.keras.layers.Flatten\n",
    "    Dense = functools.partial(tf.keras.layers.Dense, activation=\"relu\")\n",
    "\n",
    "    inp = tf.keras.Input((64, 64, 3))\n",
    "    x = Conv2D(filters=1 * n_filters, kernel_size=5, strides=2)(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters=2 * n_filters, kernel_size=5, strides=2)(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters=4 * n_filters, kernel_size=5, strides=2)(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(filters=6 * n_filters, kernel_size=5, strides=2)(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = Dense(n_outputs, activation=None, name=\"dense2\")(x)\n",
    "\n",
    "    return tf.keras.Model(inp, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_face_decoder_network():\n",
    "    # Functionally define the different layer types we will use\n",
    "    Conv2DTranspose = functools.partial(\n",
    "        tf.keras.layers.Conv2DTranspose, padding=\"same\", activation=\"relu\"\n",
    "    )\n",
    "    BatchNormalization = tf.keras.layers.BatchNormalization\n",
    "    Flatten = tf.keras.layers.Flatten\n",
    "    Dense = functools.partial(tf.keras.layers.Dense, activation=\"relu\")\n",
    "    Reshape = tf.keras.layers.Reshape\n",
    "\n",
    "    # Build the decoder network using the Sequential API\n",
    "    decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            # Transform to pre-convolutional generation\n",
    "            Dense(units=4 * 4 * 6 * n_filters),  # 4x4 feature maps (with 6N occurances)\n",
    "            Reshape(target_shape=(4, 4, 6 * n_filters)),\n",
    "            # Upscaling convolutions (inverse of encoder)\n",
    "            Conv2DTranspose(filters=4 * n_filters, kernel_size=3, strides=2),\n",
    "            Conv2DTranspose(filters=2 * n_filters, kernel_size=3, strides=2),\n",
    "            Conv2DTranspose(filters=1 * n_filters, kernel_size=5, strides=2),\n",
    "            Conv2DTranspose(filters=3, kernel_size=5, strides=2),\n",
    "        ]\n",
    "    )\n",
    "    decoder.build((None, latent_dim,))\n",
    "    return decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "batch_size = 32\n",
    "num_epochs = 2  # keep small to run faster\n",
    "learning_rate = 1e-5\n",
    "\n",
    "data_path = tf.keras.utils.get_file(\n",
    "    \"train_face.h5\", \"https://www.dropbox.com/s/hlz8atheyozp1yx/train_face.h5?dl=1\"\n",
    ")\n",
    "dataloader = TrainingDatasetLoader(data_path, batch_size=batch_size)\n",
    "\n",
    "standard_classifier = make_standard_classifier()\n",
    "\n",
    "wrapped_classifier = VAEWrapper(\n",
    "    standard_classifier,\n",
    "    decoder=make_face_decoder_network(),\n",
    "    latent_dim=latent_dim,\n",
    "    epistemic=False,\n",
    ")\n",
    "\n",
    "wrapped_classifier.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "history = wrapped_classifier.fit(\n",
    "    dataloader,\n",
    "    epochs=num_epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[HistogramCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mitdeeplearning as mdl\n",
    "\n",
    "test_faces = mdl.lab2.get_test_faces()\n",
    "all_outs = [wrapped_classifier(np.array(x, dtype=np.float32)) for x in test_faces]\n",
    "# predictions = all_outs\n",
    "predictions = [out[0] for out in all_outs]\n",
    "biases = [out[1] for out in all_outs]\n",
    "\n",
    "keys = [\"Light Female\", \"Light Male\", \"Dark Female\", \"Dark Male\"]\n",
    "for group, key in zip(test_faces, keys):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(np.hstack(group))\n",
    "    plt.title(key, fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.squeeze(tf.sigmoid(predictions))\n",
    "predictions = predictions.numpy().mean(1)\n",
    "biases = np.asarray(biases).mean(1)\n",
    "print(predictions)\n",
    "print(biases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
