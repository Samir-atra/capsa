<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />
<link rel="index" title="Index" href="../../genindex.html" /><link rel="search" title="Search" href="../../search.html" /><link rel="next" title="Composability (Advanced)" href="7_Composability.html" /><link rel="prev" title="High Level Introduction to Capsa with a Real World Problem" href="5_High-Dimensional-Depth.html" />

    <!-- Generated with Sphinx 6.1.3 and Furo 2022.12.07 -->
        <title>Anomaly Detection (Advanced) - capsa documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?digest=91d0f0d1c444bdcb17a68e833c7a53903343c195" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">capsa  documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../index.html">
  
  
  <span class="sidebar-brand-text">capsa  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../introduction/index.html">üëã Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/installation.html">üíæ Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../risk_metrics/index.html">‚≠êÔ∏è Risk Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/basic_usage.html">üé¨ Basic Usage</a></li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../index.html">üë©‚Äçüè´ Tutorials</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="1_Ensemble-Classification.html">Ensemble Wrapper (Classification)</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_Histogram-Classification.html">Histogram Wrapper (Classification)</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_MVE-Classification.html">MVE Wrapper (Classification)</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_MVE-Regression.html">MVE Wrapper (Regression)</a></li>
<li class="toctree-l2"><a class="reference internal" href="5_High-Dimensional-Depth.html">High Level Introduction to Capsa with a Real World Problem</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Anomaly Detection (Advanced)</a></li>
<li class="toctree-l2"><a class="reference internal" href="7_Composability.html">Composability (Advanced)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../api_documentation/index.html">‚Äçüíª Metric Wrapper API</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../api_documentation/BaseWrapper.html">BaseWrapper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api_documentation/RiskTensor.html">RiskTensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api_documentation/MVEWrapper.html">MVEWrapper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api_documentation/VAEWrapper.html">VAEWrapper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api_documentation/EnsembleWrapper.html">EnsembleWrapper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api_documentation/DropoutWrapper.html">DropoutWrapper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api_documentation/HistogramWrapper.html">HistogramWrapper</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../api_documentation/HistogramVAEWrapper.html">HistogramVAEWrapper</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">üßø Contribute</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<p><img alt="afbd1d57e6e74ac6aec2509620ce5092" src="https://i.ibb.co/2P3SLwK/colab.png" /> <a class="reference external" href="https://colab.research.google.com/github/themis-ai/capsa/blob/main/notebooks/6_OOD-Detection.ipynb">Run In Google Colab</a></p>
<section id="Anomaly-Detection-(Advanced)">
<h1>Anomaly Detection (Advanced)<a class="headerlink" href="#Anomaly-Detection-(Advanced)" title="Permalink to this heading">#</a></h1>
<p>It is critical for a model to recognize that it is presented with an unreasonable input e.g.¬†out of distribution (OOD); in the real world this could be used for an autonomous vehicle yielding control to a human if the perception system detects that it is presented with such an input image as it is expected that model‚Äôs performance on this datapoint will be poor. If we‚Äôre sucessful in detecting such a distribution shift, model can pass this information downstream to avoid potentially disastrous
prediction before it actually happens.</p>
<p>In this tutorial we will leverage the ‚Äúuncertainty estimation‚Äù functionality provided by capsa for anomaly detection.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!pip install capsa

# download helper functions for this tutorial
!git clone --depth 1 https://github.com/themis-ai/capsa.git
%cd /content/capsa/notebooks/utils/depth

# download and extract datasets
!wget -q http://argo-1.themisai.io/demos/nyu_depth/nyu.h5
!wget -q http://6.869.csail.mit.edu/fa17/miniplaces/data.tar.gz
!mkdir miniplaces &amp; tar -xzf data.tar.gz -C miniplaces
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import tensorflow as tf
import config as config
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from utils import get_datasets
ds_train, ds_test, ds_ood = get_datasets(
    id_path = &quot;nyu.h5&quot;,
    ood_path = &quot;miniplaces&quot;,
)
</pre></div>
</div>
</div>
<section id="Train-model">
<h2>Train model<a class="headerlink" href="#Train-model" title="Permalink to this heading">#</a></h2>
<p>We‚Äôll use the same ‚Äúbase model‚Äù as in the previous tutorial (part 5). Let‚Äôs also use <a class="reference external" href="https://themisai.io/capsa/api_documentation/EnsembleWrapper.html">EnsembleWrapper</a> to estimate epistemic uncertainty of the model. Same as with any other Capsa wrapper, user could simply wrap their model with it. This method of estimating the model uncertainty is accurate, although it‚Äôs very computationally expensive. Luckily, capsa implements multiple different epistemic wrappers.</p>
<p>‚≠ê Please feel free to experiment and in the cell below instead of the EnsembleWrapper use one of the following <code class="docutils literal notranslate"><span class="pre">Capsa</span></code> epistemic wrappers: <a class="reference external" href="https://themisai.io/capsa/api_documentation/DropoutWrapper.html">DropoutWrapper</a>, <a class="reference external" href="https://themisai.io/capsa/api_documentation/VAEWrapper.html">VAEWrapper</a>.</p>
<p>For example this is how we can initialize the <code class="docutils literal notranslate"><span class="pre">DropoutWrapper</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">capsa</span> <span class="kn">import</span> <span class="n">DropoutWrapper</span>

<span class="n">base_model</span> <span class="o">=</span> <span class="n">unet</span><span class="p">(</span><span class="n">drop_prob</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="c1"># don&#39;t add dropout in the wrapper because our</span>
<span class="c1"># model already contains dropout layers</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
</pre></div>
</div>
<p>Or the <code class="docutils literal notranslate"><span class="pre">VAEWrapper</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">capsa</span> <span class="kn">import</span> <span class="n">VAEWrapper</span>
<span class="kn">from</span> <span class="nn">models</span> <span class="kn">import</span> <span class="n">get_encoder</span><span class="p">,</span> <span class="n">get_decoder</span>

<span class="n">base_model</span> <span class="o">=</span> <span class="n">get_encoder</span><span class="p">(</span><span class="n">out_units</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">decoder</span> <span class="o">=</span> <span class="n">get_decoder</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">VAEWrapper</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">)</span>
</pre></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from models import unet
from capsa import EnsembleWrapper

base_model = unet()
model = EnsembleWrapper(base_model, num_members=3)

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=config.LR),
    loss=&quot;mse&quot;,
)
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>history = model.fit(
    ds_train,
    epochs=config.EP,
    validation_data=ds_test,
)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 1/20
256/256 [==============================] - 59s 204ms/step - usermodel_0_compiled_loss: 0.0830 - usermodel_1_compiled_loss: 0.0887 - usermodel_2_compiled_loss: 0.0850 - average_loss: 0.0856 - val_usermodel_0_compiled_loss: 0.0560 - val_usermodel_1_compiled_loss: 0.0564 - val_usermodel_2_compiled_loss: 0.0566
Epoch 2/20
256/256 [==============================] - 53s 206ms/step - usermodel_0_compiled_loss: 0.0492 - usermodel_1_compiled_loss: 0.0500 - usermodel_2_compiled_loss: 0.0500 - average_loss: 0.0497 - val_usermodel_0_compiled_loss: 0.0427 - val_usermodel_1_compiled_loss: 0.0439 - val_usermodel_2_compiled_loss: 0.0436
Epoch 3/20
256/256 [==============================] - 53s 207ms/step - usermodel_0_compiled_loss: 0.0378 - usermodel_1_compiled_loss: 0.0393 - usermodel_2_compiled_loss: 0.0385 - average_loss: 0.0385 - val_usermodel_0_compiled_loss: 0.0333 - val_usermodel_1_compiled_loss: 0.0348 - val_usermodel_2_compiled_loss: 0.0338
Epoch 4/20
256/256 [==============================] - 53s 207ms/step - usermodel_0_compiled_loss: 0.0300 - usermodel_1_compiled_loss: 0.0315 - usermodel_2_compiled_loss: 0.0304 - average_loss: 0.0306 - val_usermodel_0_compiled_loss: 0.0269 - val_usermodel_1_compiled_loss: 0.0283 - val_usermodel_2_compiled_loss: 0.0272
Epoch 5/20
256/256 [==============================] - 53s 208ms/step - usermodel_0_compiled_loss: 0.0246 - usermodel_1_compiled_loss: 0.0258 - usermodel_2_compiled_loss: 0.0248 - average_loss: 0.0251 - val_usermodel_0_compiled_loss: 0.0225 - val_usermodel_1_compiled_loss: 0.0235 - val_usermodel_2_compiled_loss: 0.0226
Epoch 6/20
256/256 [==============================] - 53s 208ms/step - usermodel_0_compiled_loss: 0.0208 - usermodel_1_compiled_loss: 0.0218 - usermodel_2_compiled_loss: 0.0209 - average_loss: 0.0212 - val_usermodel_0_compiled_loss: 0.0192 - val_usermodel_1_compiled_loss: 0.0202 - val_usermodel_2_compiled_loss: 0.0193
Epoch 7/20
256/256 [==============================] - 53s 208ms/step - usermodel_0_compiled_loss: 0.0180 - usermodel_1_compiled_loss: 0.0189 - usermodel_2_compiled_loss: 0.0181 - average_loss: 0.0183 - val_usermodel_0_compiled_loss: 0.0169 - val_usermodel_1_compiled_loss: 0.0176 - val_usermodel_2_compiled_loss: 0.0169
Epoch 8/20
256/256 [==============================] - 53s 208ms/step - usermodel_0_compiled_loss: 0.0159 - usermodel_1_compiled_loss: 0.0167 - usermodel_2_compiled_loss: 0.0160 - average_loss: 0.0162 - val_usermodel_0_compiled_loss: 0.0151 - val_usermodel_1_compiled_loss: 0.0157 - val_usermodel_2_compiled_loss: 0.0151
Epoch 9/20
256/256 [==============================] - 53s 208ms/step - usermodel_0_compiled_loss: 0.0143 - usermodel_1_compiled_loss: 0.0149 - usermodel_2_compiled_loss: 0.0143 - average_loss: 0.0145 - val_usermodel_0_compiled_loss: 0.0136 - val_usermodel_1_compiled_loss: 0.0142 - val_usermodel_2_compiled_loss: 0.0136
Epoch 10/20
256/256 [==============================] - 53s 208ms/step - usermodel_0_compiled_loss: 0.0130 - usermodel_1_compiled_loss: 0.0136 - usermodel_2_compiled_loss: 0.0130 - average_loss: 0.0132 - val_usermodel_0_compiled_loss: 0.0125 - val_usermodel_1_compiled_loss: 0.0130 - val_usermodel_2_compiled_loss: 0.0124
Epoch 11/20
256/256 [==============================] - 53s 208ms/step - usermodel_0_compiled_loss: 0.0120 - usermodel_1_compiled_loss: 0.0125 - usermodel_2_compiled_loss: 0.0119 - average_loss: 0.0121 - val_usermodel_0_compiled_loss: 0.0115 - val_usermodel_1_compiled_loss: 0.0120 - val_usermodel_2_compiled_loss: 0.0115
Epoch 12/20
256/256 [==============================] - 53s 208ms/step - usermodel_0_compiled_loss: 0.0111 - usermodel_1_compiled_loss: 0.0115 - usermodel_2_compiled_loss: 0.0110 - average_loss: 0.0112 - val_usermodel_0_compiled_loss: 0.0107 - val_usermodel_1_compiled_loss: 0.0111 - val_usermodel_2_compiled_loss: 0.0106
Epoch 13/20
256/256 [==============================] - 53s 208ms/step - usermodel_0_compiled_loss: 0.0103 - usermodel_1_compiled_loss: 0.0107 - usermodel_2_compiled_loss: 0.0103 - average_loss: 0.0104 - val_usermodel_0_compiled_loss: 0.0099 - val_usermodel_1_compiled_loss: 0.0103 - val_usermodel_2_compiled_loss: 0.0099
Epoch 14/20
256/256 [==============================] - 53s 208ms/step - usermodel_0_compiled_loss: 0.0096 - usermodel_1_compiled_loss: 0.0100 - usermodel_2_compiled_loss: 0.0096 - average_loss: 0.0098 - val_usermodel_0_compiled_loss: 0.0093 - val_usermodel_1_compiled_loss: 0.0097 - val_usermodel_2_compiled_loss: 0.0093
Epoch 15/20
256/256 [==============================] - 53s 208ms/step - usermodel_0_compiled_loss: 0.0091 - usermodel_1_compiled_loss: 0.0095 - usermodel_2_compiled_loss: 0.0091 - average_loss: 0.0092 - val_usermodel_0_compiled_loss: 0.0088 - val_usermodel_1_compiled_loss: 0.0092 - val_usermodel_2_compiled_loss: 0.0088
Epoch 16/20
256/256 [==============================] - 53s 208ms/step - usermodel_0_compiled_loss: 0.0086 - usermodel_1_compiled_loss: 0.0089 - usermodel_2_compiled_loss: 0.0086 - average_loss: 0.0087 - val_usermodel_0_compiled_loss: 0.0084 - val_usermodel_1_compiled_loss: 0.0087 - val_usermodel_2_compiled_loss: 0.0083
Epoch 17/20
256/256 [==============================] - 53s 208ms/step - usermodel_0_compiled_loss: 0.0083 - usermodel_1_compiled_loss: 0.0085 - usermodel_2_compiled_loss: 0.0081 - average_loss: 0.0083 - val_usermodel_0_compiled_loss: 0.0081 - val_usermodel_1_compiled_loss: 0.0082 - val_usermodel_2_compiled_loss: 0.0079
Epoch 18/20
256/256 [==============================] - 53s 207ms/step - usermodel_0_compiled_loss: 0.0079 - usermodel_1_compiled_loss: 0.0080 - usermodel_2_compiled_loss: 0.0077 - average_loss: 0.0079 - val_usermodel_0_compiled_loss: 0.0077 - val_usermodel_1_compiled_loss: 0.0078 - val_usermodel_2_compiled_loss: 0.0076
Epoch 19/20
256/256 [==============================] - 53s 208ms/step - usermodel_0_compiled_loss: 0.0075 - usermodel_1_compiled_loss: 0.0077 - usermodel_2_compiled_loss: 0.0074 - average_loss: 0.0075 - val_usermodel_0_compiled_loss: 0.0073 - val_usermodel_1_compiled_loss: 0.0075 - val_usermodel_2_compiled_loss: 0.0072
Epoch 20/20
256/256 [==============================] - 53s 208ms/step - usermodel_0_compiled_loss: 0.0072 - usermodel_1_compiled_loss: 0.0074 - usermodel_2_compiled_loss: 0.0071 - average_loss: 0.0072 - val_usermodel_0_compiled_loss: 0.0070 - val_usermodel_1_compiled_loss: 0.0072 - val_usermodel_2_compiled_loss: 0.0069
</pre></div></div>
</div>
<p>Perfect! We‚Äôve traind our risk-aware model, now let‚Äôs look at the loss curves.</p>
<p>As you may notice in addition to the loss metrics specified in compalation step <code class="docutils literal notranslate"><span class="pre">Capsa</span></code> also logs some additional losses these are computed under the hood to enable this risk aware functionality mentioned earlier.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from utils import plot_loss
plot_loss(history)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_notebooks_6_OOD-Detection_10_0.png" src="../../_images/tutorials_notebooks_6_OOD-Detection_10_0.png" />
</div>
</div>
<p>Let‚Äôs visualize model predictions. We see that for the out of distribution data (OOD) the model outputs a consistently high risk estimate, thus the model has successfully identified when its predictions cannot be trusted.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from utils import vis_depth_map
vis_depth_map(model, ds_test, ds_ood)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_notebooks_6_OOD-Detection_12_0.png" src="../../_images/tutorials_notebooks_6_OOD-Detection_12_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_notebooks_6_OOD-Detection_12_1.png" src="../../_images/tutorials_notebooks_6_OOD-Detection_12_1.png" />
</div>
</div>
<p>Let‚Äôs look at the calibration plot that the model produces to quantitatively assess the quality of the risk estimate.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from capsa.utils import gen_calibration_plot
gen_calibration_plot(model, ds_test)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_notebooks_6_OOD-Detection_14_0.png" src="../../_images/tutorials_notebooks_6_OOD-Detection_14_0.png" />
</div>
</div>
</section>
<section id="Anomaly-detection">
<h2>Anomaly detection<a class="headerlink" href="#Anomaly-detection" title="Permalink to this heading">#</a></h2>
<p>The core idea behind the approach is that a model‚Äôs epistemic uncertainty on out-of-distribution (OOD) data is naturally higher than the same model‚Äôs epistemic uncertainty on indistribution (ID) data. Thus, given a risk aware model we can visualize density histograms of per image uncertainty estimates provided by a model on both ID (unseen test-set for NYU Depth V2 dataset) and OOD data (MiniPlaces).</p>
<p>In other words, we would expect that the epistemic uncertainty estimate will help us to separate the out-of-distribution data.</p>
<p>Let‚Äôs plot the histogram and see‚Ä¶</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from utils import gen_ood_comparison
iid_risk, ood_risk = gen_ood_comparison(ds_test, ds_ood, model, reduce=&#39;per_img&#39;, is_show=True, is_return=True)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_notebooks_6_OOD-Detection_17_0.png" src="../../_images/tutorials_notebooks_6_OOD-Detection_17_0.png" />
</div>
</div>
<p>ü§© Amazing! Indeed, we see that the out-of-distribution datapoints have higher model uncertainty and we see two clearly pronounced peaks corresponding to the different datasets.</p>
<p>At this point, OOD (anomaly) detection is possible by a simple thresholding. We can use AUC-ROC to quantitatively assess the separation of the two density histograms, a higher AUC indicates a better quality of the separation.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from utils import plot_roc
plot_roc(iid_risk, ood_risk, model.metric_name)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_notebooks_6_OOD-Detection_19_0.png" src="../../_images/tutorials_notebooks_6_OOD-Detection_19_0.png" />
</div>
</div>
</section>
<section id="Adversarial-perturbations">
<h2>Adversarial perturbations<a class="headerlink" href="#Adversarial-perturbations" title="Permalink to this heading">#</a></h2>
<p>Further, the approach described above could be used to detect adversarial attacks (perturbations). A way of interpreting the adversarial perturbations is as a way of gradually turning ID data points into OOD. Such a granular control allows for a better model introspection.</p>
<p>After we‚Äôve trained the model, we compute gradients with respect to the input image and apply it with varying epsilon. In other words, the approach is:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>for each test image, compute gx = dL/dx (the gradient of the loss with respect to the input image pixels)
for different levels of adversarial noise k = [0, ..., 0.1]:
 perturb the test images:  x_new = x_old + k * tf.sign(gx)
 run the model on these images and compute predictions and risk estimate
</pre></div>
</div>
<p>The cell below simply implements the pseudocode above and caches the predictions.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from adversarial import get_adversarial_predictions
df_risk, risk_id, list_risk_ood, list_vis = get_adversarial_predictions(model, ds_test)
</pre></div>
</div>
</div>
<p>Simularly as we did earlier, let‚Äôs visualize density histograms of per image uncertainty estimates provided by a model on both the test data (in distribution) and the preturbed data (out of distribution).</p>
<p>We see that as the epsilon of the perturbation increases the density histograms of per image uncertainty estimates provided by a model on both the ID and perturbed images become more disentangled and thus the quality of separation increases.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import matplotlib.pyplot as plt
import seaborn as sns

fig, ax = plt.subplots(figsize=(8, 5))
plot = sns.histplot(data=df_risk, kde=True, bins=50, alpha=0.6, linewidth=0, palette=&quot;mako&quot;)
plot.set(xlabel=&quot;Epistemic risk&quot;, ylabel=&quot;PDF&quot;)
plt.show()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_notebooks_6_OOD-Detection_25_0.png" src="../../_images/tutorials_notebooks_6_OOD-Detection_25_0.png" />
</div>
</div>
<p>Simularly as we did earlier let‚Äôs use AUC-ROC to quantitatively assess the separation of the two density histograms, a higher AUC indicates a better quality of the separation.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>model_name = model.metric_name
plot_roc(risk_id, list_risk_ood, model_name, is_palette=True)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_notebooks_6_OOD-Detection_27_0.png" src="../../_images/tutorials_notebooks_6_OOD-Detection_27_0.png" />
</div>
</div>
<p>Finally, let‚Äôs visualize the images perturbed with varying degrees. We plot the input to the model on the first row; model‚Äôs predictions on the second row; and the risk estimate (outputed by the model) on the third row.</p>
<p>We see that even though some of the perturbed images are not immediately distinguishable to a human eye, the method described above successfully detects the altered input images. We also see that as the more the image becomes an out of distribution, the more the depth estimate degrades.</p>
<p>Luckily, since our model is risk aware we‚Äôre able to capture the model‚Äôs uncertainty in its predictions.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from adversarial import visualize_adversarial
visualize_adversarial(list_vis)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/tutorials_notebooks_6_OOD-Detection_29_0.png" src="../../_images/tutorials_notebooks_6_OOD-Detection_29_0.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="7_Composability.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Composability (Advanced)</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="5_High-Dimensional-Depth.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">High Level Introduction to <code class="docutils literal notranslate"><span class="pre">Capsa</span></code> with a Real World Problem</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, Themis AI Inc
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Anomaly Detection (Advanced)</a><ul>
<li><a class="reference internal" href="#Train-model">Train model</a></li>
<li><a class="reference internal" href="#Anomaly-detection">Anomaly detection</a></li>
<li><a class="reference internal" href="#Adversarial-perturbations">Adversarial perturbations</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/scripts/furo.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>